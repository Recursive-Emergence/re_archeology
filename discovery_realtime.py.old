#!/usr/bin/env python3
"""
Real-time Windmill Discovery with WebSocket Updates

This script runs the windmill discovery process and emits real-time updates
via WebSocket for visualization in the frontend map interface.
"""

import sys
import os
import logging
import numpy as np
import json
from datetime import datetime
import asyncio
import websockets
import time
from typing import Optional, Dict, Any
import ee

# Add current directory to path for imports
sys.path.append('/media/im3/plus/lab4/RE/re_archaeology')
sys.path.append('.')

from phi0_core import PhiZeroStructureDetector, ElevationPatch, DetectionResult

# Global variable to track Earth Engine initialization status
_ee_initialized = False

# Configure logging
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

# Global WebSocket connection for updates
websocket_connection = None

# Training sites
ZAANSE_SCHANS_TRAINING = [
    {"name": "De Kat", "lat": 52.47505310183309, "lon": 4.8177388422949585},
    {"name": "De Zoeker", "lat": 52.47585604112108, "lon": 4.817647238879872},
    {"name": "Het Jonge Schaap", "lat": 52.476263113476264, "lon": 4.816716787814995}
]

def initialize_earth_engine():
    """Initialize Earth Engine with service account authentication"""
    global _ee_initialized
    
    if _ee_initialized:
        return  # Already initialized, skip
        
    try:
        # Try service account first (preferred for production)
        service_account_path = "/media/im3/plus/lab4/RE/re_archaeology/sage-striker-294302-b89a8b7e205b.json"
        if os.path.exists(service_account_path):
            credentials = ee.ServiceAccountCredentials(
                'elevation-pattern-detection@sage-striker-294302.iam.gserviceaccount.com',
                service_account_path
            )
            ee.Initialize(credentials)
            logger.info("✅ Earth Engine initialized with service account credentials")
        else:
            # Fallback to default authentication
            ee.Initialize()
            logger.info("✅ Earth Engine initialized with default authentication")
        
        _ee_initialized = True
            
    except Exception as ee_error:
        logger.error(f"❌ Earth Engine initialization failed: {ee_error}")
        try:
            logger.info("Trying authentication...")
            ee.Authenticate()
            ee.Initialize()
            logger.info("✅ Earth Engine authenticated and initialized")
            _ee_initialized = True
        except Exception as auth_error:
            logger.error(f"❌ Authentication also failed: {auth_error}")
            raise Exception(f"Earth Engine setup failed: {auth_error}")

def clean_patch_data(elevation_data: np.ndarray) -> np.ndarray:
    """Replace NaNs with mean of valid values"""
    if np.isnan(elevation_data).any():
        valid_mask = ~np.isnan(elevation_data)
        if np.any(valid_mask):
            mean_elevation = np.mean(elevation_data[valid_mask])
            elevation_data = np.where(np.isnan(elevation_data), mean_elevation, elevation_data)
        else:
            # If all values are NaN, use a default elevation
            elevation_data = np.full_like(elevation_data, 2.0)
    return elevation_data

def load_focused_discovery_patch(lat, lon, buffer_radius_m=20, resolution_m=0.5, use_fallback=False):
    """
    Load elevation patch using Earth Engine with timeout protection and fallback.
    
    Args:
        lat, lon: Center coordinates for the patch
        buffer_radius_m: Radius around center in meters (default 20m)
        resolution_m: Resolution in meters (default 0.5m)
        use_fallback: If True, skip Earth Engine and use synthetic data for testing
    
    Returns:
        ElevationPatch object with focused elevation data, or None if no data
    """
    if use_fallback:
        logger.debug(f"Using fallback test data for discovery at ({lat:.4f}, {lon:.4f})")
        target_size = int((buffer_radius_m * 2) / resolution_m)
        
        # Create realistic synthetic elevation data
        elevation_array = np.random.rand(target_size, target_size) * 1.5 + 2.0  # 2-3.5m base elevation
        
        # Randomly add windmill-like features (10% chance)
        if np.random.random() < 0.1:  # 10% chance of windmill-like feature
            center_i, center_j = target_size // 2, target_size // 2
            
            # Create a small circular elevated area for potential windmill base
            for i in range(target_size):
                for j in range(target_size):
                    dist = np.sqrt((i - center_i)**2 + (j - center_j)**2)
                    if dist < 3:  # Small windmill base (3 pixel radius)
                        elevation_array[i, j] += 0.8 * np.exp(-dist/2)  # Gradual elevation increase
        
        # Add some terrain variation
        x, y = np.meshgrid(np.linspace(0, 2*np.pi, target_size), np.linspace(0, 2*np.pi, target_size))
        terrain_variation = 0.1 * np.sin(x) * np.cos(y)
        elevation_array += terrain_variation
        
        patch = ElevationPatch(
            elevation_data=elevation_array,
            lat=lat,
            lon=lon,
            source="synthetic_discovery_data",
            resolution_m=resolution_m
        )
        return patch
    
    # Ensure Earth Engine is initialized (only initialize once)
    global _ee_initialized
    if not _ee_initialized:
        try:
            initialize_earth_engine()
        except Exception as ee_error:
            logger.warning(f"Earth Engine initialization failed: {ee_error}")
            return None
        
    try:
        logger.debug(f"Loading REAL AHN4 data at ({lat:.4f}, {lon:.4f})")
        
        # Create geometry using the CONFIRMED method from validation
        center = ee.Geometry.Point([lon, lat])
        polygon = center.buffer(buffer_radius_m).bounds()
        
        # Load AHN4 DSM data (includes windmill structures) for accurate windmill detection
        ahn4_dsm = ee.ImageCollection("AHN/AHN4").select('dsm').median()
        ahn4_dsm = ahn4_dsm.reproject(crs='EPSG:28992', scale=resolution_m)
        
        # Use sampleRectangle to fetch the entire grid in one request (CONFIRMED METHOD)
        rect = ahn4_dsm.sampleRectangle(region=polygon, defaultValue=-9999, properties=[])
        
        # Add timeout protection for Earth Engine API call
        try:
            import signal
            
            def timeout_handler(signum, frame):
                raise TimeoutError("Earth Engine API call timed out")
            
            # Set timeout for Earth Engine call (10 seconds)
            signal.signal(signal.SIGALRM, timeout_handler)
            signal.alarm(10)
            
            elev_block = rect.get('dsm').getInfo()
            
            # Cancel timeout if successful
            signal.alarm(0)
            
        except (TimeoutError, Exception) as timeout_error:
            signal.alarm(0)  # Cancel timeout
            logger.debug(f"Earth Engine timeout/error at ({lat:.4f}, {lon:.4f}): {timeout_error}")
            return None
            
        elevation_array = np.array(elev_block, dtype=np.float32)
        
        # Replace sentinel value with np.nan for further processing (CONFIRMED METHOD)
        elevation_array = np.where(elevation_array == -9999, np.nan, elevation_array)
        
        # Clean the patch data using the confirmed method
        elevation_array = clean_patch_data(elevation_array)
        
        # Create ElevationPatch object using the confirmed structure
        patch = ElevationPatch(
            elevation_data=elevation_array,
            lat=lat,
            lon=lon,
            source="AHN4_real",
            resolution_m=resolution_m
        )
        
        logger.debug(f"✅ Loaded patch: {patch.elevation_data.shape} at ({lat:.6f}, {lon:.6f})")
        return patch
        
    except Exception as e:
        logger.debug(f"Failed to load patch at ({lat:.4f}, {lon:.4f}): {e}")
        return None

class RealTimeDiscoveryRunner:
    """Manages real-time windmill discovery with WebSocket updates"""
    
    def __init__(self, websocket_url: str = "ws://localhost:8000/ws"):
        self.websocket_url = websocket_url
        self.websocket = None
        self.session_id = f"discovery_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
        
    async def connect_websocket(self):
        """Connect to WebSocket for real-time updates"""
        try:
            self.websocket = await websockets.connect(self.websocket_url)
            logger.info(f"✅ Connected to WebSocket: {self.websocket_url}")
            return True
        except Exception as e:
            logger.warning(f"⚠️ Failed to connect to WebSocket: {e}")
            logger.info("Continuing without real-time updates...")
            return False
    
    async def send_update(self, update_data: Dict[str, Any]):
        """Send update via WebSocket"""
        if self.websocket:
            try:
                await self.websocket.send(json.dumps(update_data))
            except Exception as e:
                logger.warning(f"Failed to send WebSocket update: {e}")
        else:
            # Fallback: just log the update
            logger.info(f"UPDATE: {update_data.get('type', 'unknown')}")
    
    async def load_patch_with_updates(self, lat: float, lon: float, 
                                    buffer_radius_m: int = 40,  # Increased from 20 to 40 for efficiency (80x80 pixels)
                                    resolution_m: float = 0.5,
                                    patch_id: str = ""):
        """Load elevation patch and send update with timeout protection"""
        try:
            # Send scanning update
            await self.send_update({
                "type": "patch_scanning",
                "session_id": self.session_id,
                "patch_id": patch_id,
                "lat": lat,
                "lon": lon,
                "status": "loading",
                "timestamp": datetime.now().isoformat()
            })
            
            # Use the local patch loading function
            
            # Try real Earth Engine data first with timeout protection
            start_time = time.time()
            patch = None
            
            try:
                # Load the patch with real data
                patch = load_focused_discovery_patch(lat, lon, buffer_radius_m, resolution_m, use_fallback=False)
                load_time = time.time() - start_time
                
                # If loading took too long or failed, switch to fallback mode
                if patch is None or load_time > 8:
                    if patch is None:
                        logger.debug(f"Earth Engine failed for patch {patch_id}, using fallback")
                    else:
                        logger.debug(f"Earth Engine took {load_time:.1f}s for patch {patch_id}, using fallback for speed")
                    
                    # Use fallback synthetic data to keep scanning moving
                    patch = load_focused_discovery_patch(lat, lon, buffer_radius_m, resolution_m, use_fallback=True)
                    
            except Exception as ee_error:
                logger.debug(f"Earth Engine error for patch {patch_id}: {ee_error}, using fallback")
                # Use fallback synthetic data
                patch = load_focused_discovery_patch(lat, lon, buffer_radius_m, resolution_m, use_fallback=True)
            
            if patch is not None:
                # Calculate elevation statistics
                elevation_stats = {
                    "mean": float(np.mean(patch.elevation_data)),
                    "std": float(np.std(patch.elevation_data)),
                    "min": float(np.min(patch.elevation_data)),
                    "max": float(np.max(patch.elevation_data)),
                    "range": float(np.max(patch.elevation_data) - np.min(patch.elevation_data))
                }
                
                # Send patch loaded update
                await self.send_update({
                    "type": "patch_loaded",
                    "session_id": self.session_id,
                    "patch_id": patch_id,
                    "lat": lat,
                    "lon": lon,
                    "elevation_stats": elevation_stats,
                    "patch_shape": patch.elevation_data.shape,
                    "timestamp": datetime.now().isoformat()
                })
                
            return patch
            
        except Exception as e:
            await self.send_update({
                "type": "patch_error",
                "session_id": self.session_id,
                "patch_id": patch_id,
                "lat": lat,
                "lon": lon,
                "error": str(e),
                "timestamp": datetime.now().isoformat()
            })
            return None
    
    async def run_detection_with_updates(self, detector, patch, lat: float, lon: float, patch_id: str):
        """Run detection on patch and send updates"""
        try:
            # Send detection starting update
            await self.send_update({
                "type": "detection_starting",
                "session_id": self.session_id,
                "patch_id": patch_id,
                "lat": lat,
                "lon": lon,
                "timestamp": datetime.now().isoformat()
            })
            
            # Extract features
            features = detector.extract_octonionic_features(patch.elevation_data)
            
            # Run detection
            detection_result = detector.detect_with_geometric_validation(features, patch.elevation_data)
            
            # Determine if this is a positive detection
            is_positive = detection_result.detected and detection_result.confidence > 0.5
            
            # Create visualization data (simplified elevation matrix)
            h, w = patch.elevation_data.shape
            # Downsample for transmission efficiency
            step = max(1, min(h, w) // 20)  # Keep roughly 20x20 for visualization
            viz_elevation = patch.elevation_data[::step, ::step].tolist()
            
            # Calculate patch bounds
            patch_bounds = {
                "lat_min": lat - 0.0004,  # Approximate 40m radius
                "lat_max": lat + 0.0004,
                "lon_min": lon - 0.0005,
                "lon_max": lon + 0.0005
            }

            # Send detection result in format expected by backend
            await self.send_update({
                "type": "patch_result",
                "data": {
                    "session_id": self.session_id,
                    "patch_id": patch_id,
                    "lat": lat,
                    "lon": lon,
                    "is_positive": is_positive,
                    "confidence": float(detection_result.confidence),
                    "elevation_data": viz_elevation,
                    "patch_bounds": patch_bounds,
                    "detection_result": {
                        "psi0_score": float(detection_result.max_score),
                        "geometric_score": float(detection_result.geometric_score),
                        "detected": detection_result.detected,
                        "reason": detection_result.reason,
                        "confidence": float(detection_result.confidence)
                    },
                    "elevation_stats": {
                        "mean": float(np.mean(patch.elevation_data)),
                        "std": float(np.std(patch.elevation_data)),
                        "min": float(np.min(patch.elevation_data)),
                        "max": float(np.max(patch.elevation_data))
                    }
                },
                "timestamp": datetime.now().isoformat()
            })
            
            return detection_result, is_positive
            
        except Exception as e:
            await self.send_update({
                "type": "detection_error",
                "session_id": self.session_id,
                "patch_id": patch_id,
                "lat": lat,
                "lon": lon,
                "error": str(e),
                "timestamp": datetime.now().isoformat()
            })
            return None, False
    
    async def run_discovery_region(self, region_name: str = "Zaanse_Schans_Extended"):
        """Run discovery for a specific region with real-time updates"""
        logger.info(f"🏛️ Starting Real-time Windmill Discovery: {region_name}")
        
        # Initialize detector
        detector = PhiZeroStructureDetector(
            resolution_m=0.5,
            kernel_size=21,
            structure_type="windmill"
        )
        
        # Send session start update
        await self.send_update({
            "type": "session_started",
            "session_id": self.session_id,
            "region_name": region_name,
            "start_time": datetime.now().isoformat()
        })
        
        try:
            # Load training data (simplified for real-time demo)
            logger.info("Loading training data...")
            training_patches = []
            
            for windmill in ZAANSE_SCHANS_TRAINING:
                patch = await self.load_patch_with_updates(
                    windmill['lat'], windmill['lon'], 
                    buffer_radius_m=40,  # Use same size as validation (80x80 pixels)
                    patch_id=f"training_{windmill['name']}"
                )
                if patch:
                    training_patches.append(patch)
            
            if not training_patches:
                raise Exception("No training patches loaded")
            
            # Build kernel
            logger.info("Building detection kernel...")
            await self.send_update({
                "type": "kernel_building",
                "session_id": self.session_id,
                "training_patches": len(training_patches),
                "timestamp": datetime.now().isoformat()
            })
            
            # Check if force retrain is requested
            force_retrain = False  # Could be passed via config in the future
            
            # Learn or load kernel with persistence
            kernel = detector.learn_pattern_kernel(training_patches, use_apex_center=True, force_retrain=force_retrain)
            
            # Send kernel status update
            kernel_info = {
                "type": "kernel_ready",
                "session_id": self.session_id,
                "kernel_shape": kernel.shape if kernel is not None else None,
                "training_patches": len(training_patches),
                "was_cached": hasattr(detector, '_kernel_was_cached') and detector._kernel_was_cached,
                "timestamp": datetime.now().isoformat()
            }
            
            # Check if we can get cached kernel info
            try:
                cached_kernels = detector.get_cached_kernel_info()
                if cached_kernels:
                    latest_kernel = cached_kernels[0]  # Most recent
                    kernel_info["cached_kernel_info"] = {
                        "created": latest_kernel.get("created", "unknown"),
                        "training_patches": latest_kernel.get("training_patches", "unknown"),
                        "hash": latest_kernel.get("hash", "unknown")
                    }
            except Exception as e:
                logger.debug(f"Could not get cached kernel info: {e}")
            
            await self.send_update(kernel_info)
            
            # Define region to scan (fixed coordinates for Zaanse Schans)
            center_lat = 52.47600
            center_lon = 4.81700
            scan_radius_km = 1.0
            
            # Calculate grid - same as original discovery script
            scan_radius_deg = scan_radius_km / 111.0
            target_spacing_m = 50
            region_diameter_m = scan_radius_km * 2000
            grid_size = max(15, int(region_diameter_m / target_spacing_m))
            grid_size = min(grid_size, 40)  # Increased limit for better coverage
            
            actual_spacing_m = region_diameter_m / grid_size
            logger.info(f"Grid: {grid_size}x{grid_size}, Spacing: {actual_spacing_m:.0f}m")
            
            lat_min = center_lat - scan_radius_deg
            lat_max = center_lat + scan_radius_deg
            lon_min = center_lon - scan_radius_deg * np.cos(np.radians(center_lat))
            lon_max = center_lon + scan_radius_deg * np.cos(np.radians(center_lat))
            
            lat_points = np.linspace(lat_min, lat_max, grid_size)
            lon_points = np.linspace(lon_min, lon_max, grid_size)
            
            total_patches = grid_size * grid_size
            logger.info(f"Scanning {grid_size}x{grid_size} grid ({total_patches} patches)")
            
            # Send grid info
            await self.send_update({
                "type": "grid_defined",
                "session_id": self.session_id,
                "grid_size": grid_size,
                "total_patches": total_patches,
                "bounds": {
                    "lat_min": lat_min,
                    "lat_max": lat_max,
                    "lon_min": lon_min,
                    "lon_max": lon_max
                },
                "timestamp": datetime.now().isoformat()
            })
            
            # Scan the grid
            patch_count = 0
            positive_count = 0
            
            for lat_idx, lat in enumerate(lat_points):
                for lon_idx, lon in enumerate(lon_points):
                    patch_count += 1
                    patch_id = f"patch_{lat_idx}_{lon_idx}"
                    
                    # Progress update
                    if patch_count % 10 == 0:
                        await self.send_update({
                            "type": "progress_update",
                            "session_id": self.session_id,
                            "patches_scanned": patch_count,
                            "total_patches": total_patches,
                            "positive_detections": positive_count,
                            "progress_percent": (patch_count / total_patches) * 100,
                            "timestamp": datetime.now().isoformat()
                        })
                    
                    # Load patch
                    patch = await self.load_patch_with_updates(lat, lon, patch_id=patch_id)
                    
                    if patch:
                        # Run detection
                        detection_result, is_positive = await self.run_detection_with_updates(
                            detector, patch, lat, lon, patch_id
                        )
                        
                        if is_positive:
                            positive_count += 1
                            logger.info(f"🎯 Positive detection #{positive_count} at ({lat:.6f}, {lon:.6f})")
                    
                    # Reduce delay for faster scanning (was 0.1s, now 0.05s)
                    await asyncio.sleep(0.05)
            
            # Send completion update
            await self.send_update({
                "type": "discovery_completed",
                "session_id": self.session_id,
                "region_name": region_name,
                "total_patches": patch_count,
                "positive_detections": positive_count,
                "completion_time": datetime.now().isoformat()
            })
            
            logger.info(f"✅ Discovery completed: {positive_count} detections from {patch_count} patches")
            
        except Exception as e:
            await self.send_update({
                "type": "session_error",
                "session_id": self.session_id,
                "error": str(e),
                "timestamp": datetime.now().isoformat()
            })
            raise
    
    async def close(self):
        """Close WebSocket connection"""
        if self.websocket:
            await self.websocket.close()

async def main():
    """Main entry point for real-time discovery"""
    runner = RealTimeDiscoveryRunner()
    
    try:
        # Try to connect to WebSocket
        await runner.connect_websocket()
        
        # Run discovery
        await runner.run_discovery_region("Zaanse_Schans_Extended")
        
    except Exception as e:
        logger.error(f"Discovery failed: {e}")
        import traceback
        traceback.print_exc()
    
    finally:
        await runner.close()

async def run_realtime_discovery(config: Dict[str, Any], update_callback):
    """
    Entry point function for the backend API to run real-time discovery.
    
    Args:
        config: Configuration dictionary with discovery parameters
        update_callback: Async callback function for real-time updates
    
    Returns:
        Discovery results dictionary
    """
    logger.info("Starting real-time discovery from API request")
    
    # Create a custom runner that uses the callback instead of WebSocket
    class CallbackDiscoveryRunner(RealTimeDiscoveryRunner):
        def __init__(self, callback_func):
            # Don't call parent __init__ to avoid WebSocket setup
            self.session_id = f"discovery_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
            self.callback_func = callback_func
            
        async def send_update(self, update_data: Dict[str, Any]):
            """Send updates via callback instead of WebSocket"""
            try:
                await self.callback_func(update_data)
            except Exception as e:
                logger.error(f"Callback update failed: {e}")
                
        async def connect_websocket(self):
            """Override - no WebSocket needed"""
            pass
            
        async def close(self):
            """Override - no WebSocket to close"""
            pass
    
    # Create runner with callback
    runner = CallbackDiscoveryRunner(update_callback)
    
    try:
        # Extract region name from config
        region_name = config.get('region_name', 'Zaanse_Schans_Extended')
        
        # Run discovery
        await runner.run_discovery_region(region_name)
        
        # Return results summary
        return {
            'status': 'completed',
            'region_name': region_name,
            'session_id': runner.session_id,
            'completion_time': datetime.now().isoformat()
        }
        
    except Exception as e:
        logger.error(f"Discovery failed: {e}")
        # Send error through callback
        await update_callback({
            'type': 'session_error',
            'session_id': runner.session_id,
            'error': str(e),
            'timestamp': datetime.now().isoformat()
        })
        raise
    
    finally:
        await runner.close()

if __name__ == "__main__":
    asyncio.run(main())
